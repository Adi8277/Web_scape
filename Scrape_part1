!pip install beautifulsoup4 requests


import requests
from bs4 import BeautifulSoup

# Function to scrape product details from a single page
def scrape_products(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    products = soup.find_all('div', {'data-component-type': 's-search-result'})

    results = []
    for product in products:
        product_url = product.find('a', {'class': 'a-link-normal s-no-outline'})['href']
        product_name = product.find('span', {'class': 'a-size-medium a-color-base a-text-normal'}).text.strip()
        product_price = product.find('span', {'class': 'a-offscreen'}).text.strip()
        product_rating = product.find('span', {'class': 'a-icon-alt'}).text.strip().split()[0]
        product_reviews = product.find('span', {'class': 'a-size-base'}).text.strip()

        results.append({
            'url': product_url,
            'name': product_name,
            'price': product_price,
            'rating': product_rating,
            'reviews': product_reviews
        })

    return results

# Main scraping function
def scrape_amazon_products(keyword, num_pages):
    base_url = f'https://www.amazon.in/s?k={keyword}&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_'
    
    all_results = []
    for page in range(1, num_pages + 1):
        url = base_url + str(page)
        results = scrape_products(url)
        all_results.extend(results)

    return all_results

# Scrape 20 pages of product listings
keyword = 'bags'
num_pages = 20
results = scrape_amazon_products(keyword, num_pages)

# Print the scraped results
for result in results:
    print('URL:', result['url'])
    print('Name:', result['name'])
    print('Price:', result['price'])
    print('Rating:', result['rating'])
    print('Reviews:', result['reviews'])
    print()




 

