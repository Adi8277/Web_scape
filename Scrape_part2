import requests
from bs4 import BeautifulSoup

# Function to scrape product details from a single page
def scrape_products(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    # Scrape additional fields
    description = soup.find('div', {'id': 'productDescription'}).text.strip() if soup.find('div', {'id': 'productDescription'}) else ''
    asin = soup.find('th', text='ASIN').find_next('td').text.strip() if soup.find('th', text='ASIN') else ''
    product_description = soup.find('div', {'id': 'feature-bullets'}).ul.text.strip() if soup.find('div', {'id': 'feature-bullets'}) else ''
    manufacturer = soup.find('a', {'id': 'bylineInfo'}).text.strip() if soup.find('a', {'id': 'bylineInfo'}) else ''

    products = soup.find_all('div', {'data-component-type': 's-search-result'})

    results = []
    for product in products:
        product_url = product.find('a', {'class': 'a-link-normal s-no-outline'})['href']
        product_name = product.find('span', {'class': 'a-size-medium a-color-base a-text-normal'}).text.strip()
        product_price = product.find('span', {'class': 'a-offscreen'}).text.strip()
        product_rating = product.find('span', {'class': 'a-icon-alt'}).text.strip().split()[0]
        product_reviews = product.find('span', {'class': 'a-size-base'}).text.strip()

        results.append({
            'url': product_url,
            'name': product_name,
            'price': product_price,
            'rating': product_rating,
            'reviews': product_reviews,
            'description': description,
            'asin': asin,
            'product_description': product_description,
            'manufacturer': manufacturer
        })

    return results

# Main scraping function
def scrape_amazon_products(keyword, num_pages):
    base_url = f'https://www.amazon.in/s?k={keyword}&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_'
    
    all_results = []
    for page in range(1, num_pages + 1):
        url = base_url + str(page)
        results = scrape_products(url)
        all_results.extend(results)

    return all_results

# Scrape 20 pages of product listings
keyword = 'bags'
num_pages = 20  # Adjust the number of pages as needed
results = scrape_amazon_products(keyword, num_pages)

# Scrape additional information from individual product URLs
num_products = 200  # Adjust the number of product URLs to scrape
scraped_results = []
for result in results[:num_products]:
    product_url = 'https://www.amazon.in' + result['url']
    product_info = scrape_products(product_url)
    scraped_results.extend(product_info)

# Print the scraped results
for result in scraped_results:
    print('URL:', result['url'])
    print('Name:', result['name'])
    print('Price:', result['price'])
    print('Rating:', result['rating'])
    print('Reviews:', result['reviews'])
    print('Description:', result['description'])
    print('ASIN:', result['asin'])
    print('Product Description:', result['product_description'])
    print()
